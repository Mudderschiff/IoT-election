\chapter{Introduction}
The \ac{IoT} refers to a network of interconnected devices, objects, and systems embedded with sensors, software, and other technologies to collect and exchange data. These devices, ranging from smart appliances to industrial machines, enable communication and automation across various sectors \cite[1]{combinatorial}. However, the sharing of sensitive data raises significant concerns about the confidentiality and integrity of information in \ac{IoT} security. Additionally, the \ac{IoT} environment is characterized by limited resources, diverse standards, and network vulnerabilities, posing challenges for privacy during data aggregation and transport encryption \cite[1]{smpc}.

Data aggregation involves gathering data from multiple sources and presenting it in a summarized format. This process is crucial, for example, during data analysis but raises privacy concerns, as many systems handle sensitive data. Ensuring the privacy of aggregated data is therefore a primary concern \cite[2]{ppda-fog}. In smart metering systems, \ac{PPDA} is a leading solution for securing consumer data by aggregating smart meter data at the gateway, preventing attackers from identifying individual users information. While various security techniques have been developed, \ac{PPDA} is considered more convenient. Many data aggregation schemes use cryptographic techniques, such as homomorphic encryption and digital signatures, to encrypt consumers energy consumption data and send the ciphertext through a trusted gateway to the central distribution system \cite[113-114]{smart-meter}. Most \ac{PPDA} solutions rely on computationally intensive homomorphic encryption, making them unsuitable for resource constrained \ac{IoT} systems. In contrast, \ac{MPC} based strategies offer a collaborative solution for \ac{PPDA}, relying less on computation and more on communication and data sharing among entities \cite[1]{mpc}.

Distributed key generation/decryption. Full threshold secret sharing.
Many verifiable voting systems use the \ac{PPDA} technique of homomorphic encryption to tally ballots in a privacy-preserving manner. This method breaks the link between individual voters and their votes, keeping them secret \cite[53]{stuve-study}. A notable application of \ac{MPC} is threshold cryptography, where a set of parties performs cryptographic operations without any single party holding the secret key \cite[3]{mpc-ing}. The secret key is distributed among multiple talliers, requiring a certain number of them to collaborate to decrypt a ciphertext, a property known as distributed decryption \cite[40]{stuve-study}.



\begin{comment}
    Distributed key generation/decryption: We study the use of full and threshold secret sharing to
distribute the ElGamal key generation and decryption among different talliers such that m or
t < m of the talliers need to collaborate to decrypt a ciphertext c that was encrypted under
their joint public key pk. The algorithms that are run by individual talliers are combined with
the NIZKP for verifiable key generation and verifiable decryption (see above). For a full secret
sharing, see, for example, Protocol 7.1 (verifiable distributed key generation) and Protocol 7.8
(verifiable distributed decryption) in [58]. For verifiable threshold secret sharing, see [53, 31] \cite[41]{stuve-study}.

Single tallier, Several talliers.

Implementing a distributed key generation (DKG) is challenging (see Section 4.2.3). Therefore,
in practice many systems run a ”fake” DKG protocol on a single machine. The shares are then
distributed to each tallier to give a semblance of security. This approach degrades the evalua
tion to Level 3 since the attacker can learn the decryption key once the machine used during
the setup can be compromised. \cite[55]{stuve-study}


Furthermore, it can be expected that the trust regarding vote privacy is distributed among
multiple parties; in this way, only an (arbitrarily determinable) number of talliers must be trusted
to ensure that the individual links between voters’ encrypted votes and their choices in the final
result remain secret. We remind the reader of Key finding 2, which here implies that the talliers
must be effectively distributed. \cite[93]{stuve-study}



\cite[2]{ppda-fog}




Traditional cryptographic algorithms encounter challenges
when applied to IoT scenarios due to inherent resource limitations
such as power constraints, limited battery capacity, and the need for
real-time execution \cite[1]{smpc}.






In today’s digital world, many elections are conducted online. In such elections,
however, there is a risk that voters’ votes may be altered unnoticed by the voting system as they pass
through electronically, and therefore the will of the voters may not be accurately reflected in the final
result. End-to-end verifiability is the gold standard to address this problem. With this fundamental
property, it is possible to independently verify that the final result matches the votes received, even
if parts of the voting system do not work correctly. \cite[3]{stuve-study}

Voting device verification: There is no one-size-fits-all solution to protect against possibly cor
rupted voting devices. Which voting device verification mechanism is appropriate for a given
election depends on various election-specific requirements.

Trust assumptions: The ultimate goal of verifiable online voting systems with vote secrecy is to
reduce the required trust in the various system components as much as possible. To effectively
distribute trust in practice, it must be ensured that these parties are truly independent of each
other.

\cite[3]{stuve-study}.

End-to-end verifiability: Especially in online elections, there is a risk that votes can be digitally
altered: it is not immediately apparent whether votes have been lost, added, or changed on
the purely electronic path from the voting devices through the digital ballot box to the result
announced online. Such changes can be caused not only by intentional manipulation, but
also by unknown software bugs. However, to ensure that the final result is accepted only if
it correctly reflects the votes of the voters, even if parts of the voting system do not function
properly, the voting system must be end-to-end verifiable
\cite[6]{stuve-study}

dentification of key methods: Based on an extensive market and literature analysis, we have
selected eight key methods for end-to-end verifiable online voting that we will study in more
detail in this work. These methods differ in their purposes, underlying assumptions and cryp
tographic building blocks
\cite[7]{stuve-study}

Another fundamental challenge is to be confident that the votes cast by
voters are accurately reflected in the election result. The gold standard for meeting this challenge is
end-to-end verifiability, which can be enhanced to accountability
Since the main purpose of verifiability is
to protect against possibly corrupted parties, verifiability should (ideally) not be based on any
trust assumptions
Accountability is a stronger notion of verifiability. While verifiability enables auditors to verify
whether the final election result correctly reflects the votes chosen by the voters, verifiability
alone is not sufficient to detect which parties manipulated the final outcome. Accountability
solves this problem as it enables one to identify misbehaving parties individually and hold
these parties accountable. This property can be particularly useful in practice to resolve/avoid
possible disputes and to increase the system’s robustness
\cite[10]{stuve-study}

Since the voting devices use cryptographic techniques to keep the vot
ers’ individual choices secret, it is impossible for a human voter to directly check that their voting
device VD cast their vote as intended. There exist different techniques to empower voters to verify
that their original choices have been processed correctly. Some techniques employ, for example,
separate audit devices or applications, while others use human-readable codes.
\cite[11]{stuve-study}



This means that the purpose of verifiability is to ensure that even if one or more components of
the voting system fail to perform their tasks correctly (whether intentionally or not), it is possible to
detect that something has gone wrong. 
\cite[25]{stuve-study}

While end-to-end verifiability guarantees the correctness of the final result,
a stronger feature is desirable from a practical point of view. Namely, it is helpful to be able to
identify the party or parties responsible for the error.
This desired property is called accountability [102]. It is a stronger form of verifiability, making it
possible not only to determine whether the final result matches the votes cast, but also to identify
the responsible component (or at least limit the possible sources of error) in the event of a detected
error. Because of its practical usefulness, we will positively evaluate accountability as a bonus of
end-to-end verifiable systems.
\cite[27]{stuve-study}

while efficiency reflects the computational and communication
costs of running a voting system using that mechanism
\cite[31]{stuve-study}


This research focuses on a a practical implementation of \ac{E2E} verifiable voting systems that rely on \ac{PPDA} and \ac{MPC} techniques. In order to evaluate the feasability of running a voting system using these mechanism 

\end{comment}






\section{Ziele dieser Arbeit}

\begin{comment}
    practical application of \ac{E2E} verifiable voting systems and to that extend secure-multiparty computation protocols on resource-constrained devices is lacking. 

This reasearch aims to contribute to the literature by gaining insights into the practical application of \ac{E2E} verifiable voting systems and secure-multiparty computation protocols within the \ac{IoT environment}.


The field of SMPC has flourished with the rise of cloud computing
and data-sharing in IoT environments. However, the literature on
the practical application of SMPC protocols on resource-constrained
devices is lacking. Prior research has mostly been focused on devel-
oping secure protocols and testing them in virtual environments,
rather than on devices like an Arduino. Therefore, this research aims
to contribute to the literature by gaining insights into the practical
\end{comment}


\section{Überblick}
Der Autor führt einen potentiellen Leser durch die Arbeit und beschreibt kurz, was den Leser in den folgenden Kapiteln erwartet.



\begin{comment}

    Our study is organized as follows. In Chapter 2, we present the necessary background in
online voting and cryptography to follow our study. In Chapter 3, we introduce our four evaluation
criteria. In Chapter 4, the main work of our study, we describe and evaluate the eight different
methods we selected. In Chapter 5, we summarize and discuss our results.
    
Voter-perceived latency certainly needs to be considered, particularly if the voting device has a
slow CPU. Luckily, beyond the optimizations discussed above, there are a variety of other options
to hide this latency. For example, we also enable a precomputation approach since most of the
computation for encrypting selections and generating the ZK proofs is independent of the voter’s
selections.  \cite[23]{eg-paper}


The practicality of a voting system ensures that it can be implemented correctly in practive and that the resultin implementation is efficient enough for the intended election. 


\subsection{Usability}
Usability. The ISO standard for usability [78] considers the following aspects:
• Efficiency: This is the (total) time that users need to complete their task. In our application, 
this is the time to complete authentication, vote casting, and individual verification.
• Effectiveness: This property describes how accurately and completely users perform their task. 
In our application, there are essentially two types of potential errors: failing to cast a vote, or 
failing to apply the individual verification mechanism. The latter can be divided into failing 
to detect manipulations, or failing to report a detected manipulation to the right place.
• Satisfaction: This property measures how comfortable users found the task. In our applica
tion, this could for example be affected by voters complaining about having to use two devices.
\subsection{Implementability}
\subsection{Efficiency}
communication and computation.
main communication costs data size 
computational cost
serialization
28



\cite[10-11]{onlinee-2e-study}:


Requires person or group implementing the voting system to have skills in addition to a "standard" background of software engineer, that are required to understand the particular algorithm or to implement it corretly.
Example skills include cryptography, parallelism, secure hardware

Sources of randomness in a constrained environment
multiple interacting devices
anonymouse/untappable channels
31

The number of agents involved in the mechanism, as well as the pattern of communication between the agents, has significant impact on the effort required to implement the mechanism: more agents means that more independent pieces of software must be developed, and the communication between the agents must be managed and synchronized. Therefore, the more agents are involved and the more complex their communication is, the more negatively we evaluate this constraint. If the mechanism requires up to two more agents, we consider this few agents, otherwise we consider this many agents. 32



Implementability (Section 3.5.1) captures the effort required to implement a mechanism. 
There are various constraints (e.g., required skills, limited resources, and the complexity of 

Implementability


Constraint: resources (Table 3.2). A mechanism may rely on existing resources, physical or digital,
to enable its implementation, making the task more complex.
Examples of such resources include sources of randomness in a constrained environment, low-
latency/high-throughput network between agents, key management systems (e.g. HSM), multiple
interacting devices, anonymous/untappable channels, special printing (e.g., special paper, unusual
folding, scratch cards), or personal trusted hardware (e.g. eID).

onstraint: protocol complexity (Table 3.3). The number of agents involved in the mechanism,
as well as the pattern of communication between the agents, has a significant impact on the ef
fort required to implement the mechanism: more agents means that more independent pieces of

software must be developed, and the communication between the agents must be managed and
synchronized. Therefore, the more agents are involved and the more complex their communica
tion is, the more negatively we evaluate this constraint. If the mechanism requires up to two more
agents, we consider this few agents, otherwise we consider this many agents


Efficiency
We study two aspects of efficiency: communication and computation. We evaluate the communi
cation overhead and the computation overhead of a mechanism separately, and the minimum of
both is its overall efficiency.
In our evaluations, to estimate the data size and computation time, we will consider an election
with 100 candidates from which a voter can choose one

Communication (Table 3.5). The main communication costs of a mechanism are the size of the
data to be transferred and the complexity of the communication:
• Data size: We look at the total size of all messages and divide it by the number of voters. We
use 1 MB per voter as a definition of medium size.
• Complexity: We count the number of communication rounds, i.e. the number of times an
agent (server, voting device, audit device, …) has to wait for data from others before it can send
messages again. The higher the number of rounds, the worse the communication complexity.
If the number of rounds is in relation to the number of servers and trustees, we use some
rounds, else we use many rounds.

Computation (Table 3.6). To evaluate the computational overhead of a mechanism, we consider
a large scale election with 100,000 voters on current retail hardware. We distinguish between the
computational cost on the voters’ side and on the servers’ side.
• Voter: We assume that the voter is using a browser or app on their personal computer or
phone. We distinguish between less than 1 second, less than 1 minute, and more than 1 minute
of computation time.
• Server: We distinguish between a few minutes, a few hours, and many hours (more than five)
of computation time on a single processor. We value positively when the algorithm can be
distributed or parallelized.



We evaluate the communication efficiency (Section 3.5.2) as follows. Both approaches have data
size small. Concerning the number of blocking rounds, no threshold needs 0 rounds, while threshold
needs some rounds. This results in an overall communication efficiency score of 5 for no threshold,
and 3 for threshold. We achieve their intermediate scores as follows:
• Data size: First, we note that a single ElGamal ciphertext consists of two group elements.
When we tally the ballots with a verifiable mix net (Section 4.5), we can encrypt the complete
choice in a single ciphertext. The corresponding proof of plaintext knowledge is done with 2
scalars (see Section 5.4.1 in [58]). The ciphtertext together with the proof results therefore in
2 · 32B + 2 · 32B = 128B per ballot.
When we tally the ballots with homomorphic aggregation (Section 4.4), we consider the ap
proach of representing each choice as a binary vector, where the 1 entries indicate a voter’s
preferred candidates. Proving membership in the set {0, 1} consists of 4 scalars: 2 challenges
and 2 responses for each element in the set (see, e.g., Section 5.4 of [58]). A membership proof
is needed for each candidate as well as for the homomorphic aggregation of the candidate en
tries, which corresponds to 100 + 1 = 101 proofs for an election with 100 candidates. When
we put these numbers together, a ballot consists of 200 group elements for the encryptions
and 101 · 8 = 808 scalars for the NIZKPs. This results in 200 · 32B + 808 · 32B ≈ 32KB.
This shows that in both cases, the size of the ballot is well below our 1MB threshold, hence the
data is small.
• Complexity: With no threshold secret sharing, no blocking communication is necessary. With
threshold secret sharing, the protocol includes blocking steps impacting the communication
efficiency. As described in Section 3.1.1 of [53] and with more details in [31], 3 rounds per
tallier are required to build partial decryption keys. Assuming the usage of homomorphic
aggregation (see Section 4.4), the talliers perform the decryption in 2 rounds, which results in
a total of 5 rounds per tallier.
For no threshold secret sharing, we therefore have 0 blocking rounds, while for threshold secret
sharing, we have some blocking rounds.


We evaluate the computational efficiency (Section 3.5.2) as follows. For both approaches, the
server time is less than a few minutes, and the voter time less than a second, hence both have an
overall computational efficiency score of 5. We achieve the intermediate scores as follows:
• Server time: Only the voting server is active in the ballot submission phase and it only needs
to store (or forward) the incoming ballots.5 The time required for these operations is less than
a few minutes in total.
• Voter time: First, we note that forming a single ciphertext requires two exponentiations.
When we tally the ballots with a verifiable mix net (Section 4.5), a single ciphertext is sufficient.
The corresponding proof of plaintext knowledge requires another 2 exponentiations. Hence,
the total time to compute the ballot is therefore 4 · 0.32ms = 1.28ms.
When we tally the ballots homomorphically (Section 4.4), we again consider the approach
which results in one ciphertext per candidate (see the Data size evaluation for details). Each
membership proof requires 4 exponentiations (see, e.g., Section 5.4 of [58]: a proof of plaintext
knowledge requires 2 exponentiations, thus a membership proof for a set with 2 elements
requires 2 · 2 = 4). In an election with 100 candidates where a voter can select at most one of
them, a ballot therefore needs 200·0.32ms = 64ms to encrypt, and then 404·0.32ms = 129.3ms
to generate the NIZKP. The total ballot construction time remains clearly under 1



Trust assumptions: The ultimate goal of verifiable online voting systems with vote secrecy is to 
reduce the required trust in the various system components as much as possible. To effectively 
distribute trust in practice, it must be ensured that these parties are truly independent of each 
other.

Verifiable tallying: We can expect any state-of-the-art verifiable online voting system to com
bine a secret ballot technique with a verifiable privacy-preserving tallying technique. In this 
way, independent auditors can verify the correctness of the election result, without having to 
trust the tallying authority, while keeping individual votes secret.
• Voting device verification: There is no one-size-fits-all solution to protect against possibly cor
rupted voting devices. Which voting device verification mechanism is appropriate for a given 
election depends on various election-specific requirements.

Everlasting privacy: In many elections, it is necessary to protect privacy not only in the fore
 seeable future, but also in the long run, e.g. against quantum adversaries. There are feasible 
approaches to guarantee this property, called everlasting privacy, towards anyone who wants 
to verify the election, i.e., without compromising verifiability.

• Ballot secrecy: Every voter should be able to express their true will. Unfortunately, depending 
on the circumstances of an election, there is a risk that not every voter will be in such a posi
 tion. For example, there may be a general discomfort with open voting, since voters may fear 
that they will sooner or later be disadvantaged if they openly express their will. In this case, 
which applies to many elections, it must be ensured that voters can cast their votes in secret
 and that they must remain secret during and after the election.
 • End-to-end verifiability: Especially in online elections, there is a risk that votes can be digitally 
altered: it is not immediately apparent whether votes have been lost, added, or changed on 
the purely electronic path from the voting devices through the digital ballot box to the result 
announced online. Such changes can be caused not only by intentional manipulation, but 
also by unknown software bugs. However, to ensure that the final result is accepted only if 
it correctly reflects the votes of the voters, even if parts of the voting system do not function 
properly, the voting system must be end-to-end verifiable.




The concept of homomorphic aggregation to tally ballots in a verifiable manner is based on the ad
ditively homomorphic property of the underlying public-key encryption or commitment scheme. 
As we explained in Section 4.2 (for public-key encryption) and in Section 4.3 (for commitments), 
this feature guarantees that a list of such ciphertexts or a list of such commitments can be com
 bined in a way that the result is a single ciphertext or a single commitment that contains the sum of 
all messages in the respective list; in particular, this function is deterministic and can be performed 
by anyone without any secret knowledge (e.g., of a secret key or opening values). \cite[53]{onlinee-2e-study}.

In fact, if we use the homomorphic aggregation as sketched above, a corrupted voter Vi could 
secretly submit more than one vote (by choosing some v > 1) or remove votes to manipulate 
the election outcome (see Remark 2 for an example).





 If an online voting system aims to distribute trust among multiple entities, then special care must 
be taken to ensure that these different entities are truly independent. Distributing trust for the sake 
of appearances is not enough. Depending on the role, this may mean, for example, that the parties 
are physically separated (e.g., in distributed mix nets), that their software comes from independent 
sources (e.g., in voting device verification) and that the providers are independent (e.g., economically, 
politically).
\end{comment}