\chapter{Introduction}
In der Einleitung wird die Arbeit motiviert und die Relevanz dieser herausgearbeitet.

\section{Ziele dieser Arbeit}
Die Ziele der Arbeit werden hier erläutert. 

\section{Überblick}
Der Autor führt einen potentiellen Leser durch die Arbeit und beschreibt kurz, was den Leser in den folgenden Kapiteln erwartet.


\begin{comment}
    
Voter-perceived latency certainly needs to be considered, particularly if the voting device has a
slow CPU. Luckily, beyond the optimizations discussed above, there are a variety of other options
to hide this latency. For example, we also enable a precomputation approach since most of the
computation for encrypting selections and generating the ZK proofs is independent of the voter’s
selections.  \cite[23]{eg-paper}


The practicality of a voting system ensures that it can be implemented correctly in practive and that the resultin implementation is efficient enough for the intended election. 


\subsection{Usability}
Usability. The ISO standard for usability [78] considers the following aspects:
• Efficiency: This is the (total) time that users need to complete their task. In our application, 
this is the time to complete authentication, vote casting, and individual verification.
• Effectiveness: This property describes how accurately and completely users perform their task. 
In our application, there are essentially two types of potential errors: failing to cast a vote, or 
failing to apply the individual verification mechanism. The latter can be divided into failing 
to detect manipulations, or failing to report a detected manipulation to the right place.
• Satisfaction: This property measures how comfortable users found the task. In our applica
tion, this could for example be affected by voters complaining about having to use two devices.
\subsection{Implementability}
\subsection{Efficiency}
communication and computation.
main communication costs data size 
computational cost
serialization
28



\cite[10-11]{onlinee-2e-study}:


Requires person or group implementing the voting system to have skills in addition to a "standard" background of software engineer, that are required to understand the particular algorithm or to implement it corretly.
Example skills include cryptography, parallelism, secure hardware

Sources of randomness in a constrained environment
multiple interacting devices
anonymouse/untappable channels
31

The number of agents involved in the mechanism, as well as the pattern of communication between the agents, has significant impact on the effort required to implement the mechanism: more agents means that more independent pieces of software must be developed, and the communication between the agents must be managed and synchronized. Therefore, the more agents are involved and the more complex their communication is, the more negatively we evaluate this constraint. If the mechanism requires up to two more agents, we consider this few agents, otherwise we consider this many agents. 32



Implementability (Section 3.5.1) captures the effort required to implement a mechanism. 
There are various constraints (e.g., required skills, limited resources, and the complexity of 

Implementability


Constraint: resources (Table 3.2). A mechanism may rely on existing resources, physical or digital,
to enable its implementation, making the task more complex.
Examples of such resources include sources of randomness in a constrained environment, low-
latency/high-throughput network between agents, key management systems (e.g. HSM), multiple
interacting devices, anonymous/untappable channels, special printing (e.g., special paper, unusual
folding, scratch cards), or personal trusted hardware (e.g. eID).

onstraint: protocol complexity (Table 3.3). The number of agents involved in the mechanism,
as well as the pattern of communication between the agents, has a significant impact on the ef
fort required to implement the mechanism: more agents means that more independent pieces of

software must be developed, and the communication between the agents must be managed and
synchronized. Therefore, the more agents are involved and the more complex their communica
tion is, the more negatively we evaluate this constraint. If the mechanism requires up to two more
agents, we consider this few agents, otherwise we consider this many agents


Efficiency
We study two aspects of efficiency: communication and computation. We evaluate the communi
cation overhead and the computation overhead of a mechanism separately, and the minimum of
both is its overall efficiency.
In our evaluations, to estimate the data size and computation time, we will consider an election
with 100 candidates from which a voter can choose one

Communication (Table 3.5). The main communication costs of a mechanism are the size of the
data to be transferred and the complexity of the communication:
• Data size: We look at the total size of all messages and divide it by the number of voters. We
use 1 MB per voter as a definition of medium size.
• Complexity: We count the number of communication rounds, i.e. the number of times an
agent (server, voting device, audit device, …) has to wait for data from others before it can send
messages again. The higher the number of rounds, the worse the communication complexity.
If the number of rounds is in relation to the number of servers and trustees, we use some
rounds, else we use many rounds.

Computation (Table 3.6). To evaluate the computational overhead of a mechanism, we consider
a large scale election with 100,000 voters on current retail hardware. We distinguish between the
computational cost on the voters’ side and on the servers’ side.
• Voter: We assume that the voter is using a browser or app on their personal computer or
phone. We distinguish between less than 1 second, less than 1 minute, and more than 1 minute
of computation time.
• Server: We distinguish between a few minutes, a few hours, and many hours (more than five)
of computation time on a single processor. We value positively when the algorithm can be
distributed or parallelized.



We evaluate the communication efficiency (Section 3.5.2) as follows. Both approaches have data
size small. Concerning the number of blocking rounds, no threshold needs 0 rounds, while threshold
needs some rounds. This results in an overall communication efficiency score of 5 for no threshold,
and 3 for threshold. We achieve their intermediate scores as follows:
• Data size: First, we note that a single ElGamal ciphertext consists of two group elements.
When we tally the ballots with a verifiable mix net (Section 4.5), we can encrypt the complete
choice in a single ciphertext. The corresponding proof of plaintext knowledge is done with 2
scalars (see Section 5.4.1 in [58]). The ciphtertext together with the proof results therefore in
2 · 32B + 2 · 32B = 128B per ballot.
When we tally the ballots with homomorphic aggregation (Section 4.4), we consider the ap
proach of representing each choice as a binary vector, where the 1 entries indicate a voter’s
preferred candidates. Proving membership in the set {0, 1} consists of 4 scalars: 2 challenges
and 2 responses for each element in the set (see, e.g., Section 5.4 of [58]). A membership proof
is needed for each candidate as well as for the homomorphic aggregation of the candidate en
tries, which corresponds to 100 + 1 = 101 proofs for an election with 100 candidates. When
we put these numbers together, a ballot consists of 200 group elements for the encryptions
and 101 · 8 = 808 scalars for the NIZKPs. This results in 200 · 32B + 808 · 32B ≈ 32KB.
This shows that in both cases, the size of the ballot is well below our 1MB threshold, hence the
data is small.
• Complexity: With no threshold secret sharing, no blocking communication is necessary. With
threshold secret sharing, the protocol includes blocking steps impacting the communication
efficiency. As described in Section 3.1.1 of [53] and with more details in [31], 3 rounds per
tallier are required to build partial decryption keys. Assuming the usage of homomorphic
aggregation (see Section 4.4), the talliers perform the decryption in 2 rounds, which results in
a total of 5 rounds per tallier.
For no threshold secret sharing, we therefore have 0 blocking rounds, while for threshold secret
sharing, we have some blocking rounds.


We evaluate the computational efficiency (Section 3.5.2) as follows. For both approaches, the
server time is less than a few minutes, and the voter time less than a second, hence both have an
overall computational efficiency score of 5. We achieve the intermediate scores as follows:
• Server time: Only the voting server is active in the ballot submission phase and it only needs
to store (or forward) the incoming ballots.5 The time required for these operations is less than
a few minutes in total.
• Voter time: First, we note that forming a single ciphertext requires two exponentiations.
When we tally the ballots with a verifiable mix net (Section 4.5), a single ciphertext is sufficient.
The corresponding proof of plaintext knowledge requires another 2 exponentiations. Hence,
the total time to compute the ballot is therefore 4 · 0.32ms = 1.28ms.
When we tally the ballots homomorphically (Section 4.4), we again consider the approach
which results in one ciphertext per candidate (see the Data size evaluation for details). Each
membership proof requires 4 exponentiations (see, e.g., Section 5.4 of [58]: a proof of plaintext
knowledge requires 2 exponentiations, thus a membership proof for a set with 2 elements
requires 2 · 2 = 4). In an election with 100 candidates where a voter can select at most one of
them, a ballot therefore needs 200·0.32ms = 64ms to encrypt, and then 404·0.32ms = 129.3ms
to generate the NIZKP. The total ballot construction time remains clearly under 1



Trust assumptions: The ultimate goal of verifiable online voting systems with vote secrecy is to 
reduce the required trust in the various system components as much as possible. To effectively 
distribute trust in practice, it must be ensured that these parties are truly independent of each 
other.

Verifiable tallying: We can expect any state-of-the-art verifiable online voting system to com
bine a secret ballot technique with a verifiable privacy-preserving tallying technique. In this 
way, independent auditors can verify the correctness of the election result, without having to 
trust the tallying authority, while keeping individual votes secret.
• Voting device verification: There is no one-size-fits-all solution to protect against possibly cor
rupted voting devices. Which voting device verification mechanism is appropriate for a given 
election depends on various election-specific requirements.

Everlasting privacy: In many elections, it is necessary to protect privacy not only in the fore
 seeable future, but also in the long run, e.g. against quantum adversaries. There are feasible 
approaches to guarantee this property, called everlasting privacy, towards anyone who wants 
to verify the election, i.e., without compromising verifiability.

• Ballot secrecy: Every voter should be able to express their true will. Unfortunately, depending 
on the circumstances of an election, there is a risk that not every voter will be in such a posi
 tion. For example, there may be a general discomfort with open voting, since voters may fear 
that they will sooner or later be disadvantaged if they openly express their will. In this case, 
which applies to many elections, it must be ensured that voters can cast their votes in secret
 and that they must remain secret during and after the election.
 • End-to-end verifiability: Especially in online elections, there is a risk that votes can be digitally 
altered: it is not immediately apparent whether votes have been lost, added, or changed on 
the purely electronic path from the voting devices through the digital ballot box to the result 
announced online. Such changes can be caused not only by intentional manipulation, but 
also by unknown software bugs. However, to ensure that the final result is accepted only if 
it correctly reflects the votes of the voters, even if parts of the voting system do not function 
properly, the voting system must be end-to-end verifiable.




The concept of homomorphic aggregation to tally ballots in a verifiable manner is based on the ad
ditively homomorphic property of the underlying public-key encryption or commitment scheme. 
As we explained in Section 4.2 (for public-key encryption) and in Section 4.3 (for commitments), 
this feature guarantees that a list of such ciphertexts or a list of such commitments can be com
 bined in a way that the result is a single ciphertext or a single commitment that contains the sum of 
all messages in the respective list; in particular, this function is deterministic and can be performed 
by anyone without any secret knowledge (e.g., of a secret key or opening values). \cite[53]{onlinee-2e-study}.

In fact, if we use the homomorphic aggregation as sketched above, a corrupted voter Vi could 
secretly submit more than one vote (by choosing some v > 1) or remove votes to manipulate 
the election outcome (see Remark 2 for an example).





 If an online voting system aims to distribute trust among multiple entities, then special care must 
be taken to ensure that these different entities are truly independent. Distributing trust for the sake 
of appearances is not enough. Depending on the role, this may mean, for example, that the parties 
are physically separated (e.g., in distributed mix nets), that their software comes from independent 
sources (e.g., in voting device verification) and that the providers are independent (e.g., economically, 
politically).
\end{comment}